{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchDataPreprocessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.pitch_to_idx = {'<pad>': 0, '<start>': 1, '<arsenal>': 2}\n",
    "        self.idx_to_pitch = {0: '<pad>', 1: '<start>', 2: '<arsenal>'}\n",
    "        self.pitcher_arsenals = defaultdict(set)\n",
    "        self.max_seq_length = 0\n",
    "        self.max_arsenal_length = 8\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Create pitch type vocabulary\n",
    "        unique_pitches = set()\n",
    "        for seq in self.df['Pitch Sequence']:\n",
    "            unique_pitches.update(seq.split(','))\n",
    "        \n",
    "        for pitch in unique_pitches:\n",
    "            if pitch not in self.pitch_to_idx:\n",
    "                idx = len(self.pitch_to_idx)\n",
    "                self.pitch_to_idx[pitch] = idx\n",
    "                self.idx_to_pitch[idx] = pitch\n",
    "\n",
    "        # Create pitcher arsenals\n",
    "        for _, row in self.df.iterrows():\n",
    "            pitcher_id = row['Pitcher ID']\n",
    "            pitches = row['Pitch Sequence'].split(',')\n",
    "            self.pitcher_arsenals[pitcher_id].update(pitches)\n",
    "\n",
    "        # Find max sequence length (including <start> token)\n",
    "        # TODO(kaelen): temporarily added 9 padding spaces for arsenal length for now. Think of better way to do this.\n",
    "        self.max_seq_length = max(len(seq.split(',')) for seq in self.df['Pitch Sequence']) + 10\n",
    "\n",
    "    def encode_input(self, sequence, pitcher_id):\n",
    "        encoded_arsenals = self.encode_arsenal_for_pitcher(pitcher_id)\n",
    "        encoded_sequence = self.encode_sequence(sequence)\n",
    "        return encoded_arsenals + encoded_sequence\n",
    "    \n",
    "    def encode_arsenal_for_pitcher(self, pitcher_id):\n",
    "        arsenal = self.pitcher_arsenals[pitcher_id]\n",
    "        arsenal_ids = [self.pitch_to_idx[pitch] for pitch in arsenal]\n",
    "        # [<arsenal>, <pitches in arsenal...>, <pad (if needed)>]\n",
    "        encoded_arsenals = [2] + sorted(arsenal_ids) + [0] * (self.max_arsenal_length - len(arsenal))\n",
    "        return encoded_arsenals\n",
    "\n",
    "    def encode_sequence(self, sequence):\n",
    "        return [1] + [self.pitch_to_idx[pitch] for pitch in sequence.split(',')]\n",
    "\n",
    "    def pad_sequence(self, sequence):\n",
    "        padded = sequence + [0] * (self.max_seq_length - len(sequence))\n",
    "        return padded[:self.max_seq_length]\n",
    "\n",
    "    def get_pitcher_arsenal_mask(self, pitcher_id):\n",
    "        arsenal = self.pitcher_arsenals[pitcher_id]\n",
    "        mask = [1 if pitch in arsenal or idx < 3 else 0 for idx, pitch in self.idx_to_pitch.items()]\n",
    "        return torch.tensor(mask, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchSequenceDataset(Dataset):\n",
    "    def __init__(self, df, preprocessor):\n",
    "        self.df = df\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sequence = self.preprocessor.encode_sequence(row['Pitch Sequence'])\n",
    "        \n",
    "        input_seq = torch.tensor(sequence[:-1], dtype=torch.long)\n",
    "        target = torch.tensor(sequence[-1], dtype=torch.long)\n",
    "        \n",
    "        padded_input = self.preprocessor.pad_sequence(input_seq.tolist())\n",
    "        input_seq = torch.tensor(padded_input, dtype=torch.long)\n",
    "\n",
    "        return input_seq, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchSequenceAndPitcherDataset(Dataset):\n",
    "    def __init__(self, df, preprocessor):\n",
    "        self.df = df\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        pitcher_id = row['Pitcher ID']\n",
    "        raw_sequence = row['Pitch Sequence']\n",
    "        encoded_input = self.preprocessor.encode_input(raw_sequence, pitcher_id)\n",
    "        \n",
    "        # Strip off the last pitch from our sequence and make it the target pitch we want to predict. \n",
    "        input_seq = torch.tensor(encoded_input[:-1], dtype=torch.long)\n",
    "        target = torch.tensor(encoded_input[-1], dtype=torch.long)\n",
    "        \n",
    "        padded_input = self.preprocessor.pad_sequence(input_seq.tolist())\n",
    "        input_seq = torch.tensor(padded_input, dtype=torch.long)\n",
    "        \n",
    "        return input_seq, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dropout=0.1):\n",
    "        super(PitchTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = nn.Embedding(1000, d_model)  # Assuming max sequence length < 1000\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead, dropout=dropout),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        src = self.embedding(src)\n",
    "        pos = torch.arange(0, src.size(1), dtype=torch.long, device=src.device).unsqueeze(0)\n",
    "        src = src + self.pos_encoder(pos)\n",
    "        output = self.transformer(src, src_key_padding_mask=src_mask)\n",
    "        return self.fc(output[:, -1, :])  # Only use the last position for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchPredictor:\n",
    "    def __init__(self, model, preprocessor):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def get_input_sequence_for_pitcher_prediction(self, sequence, pitcher_id):\n",
    "        encoded_input = self.preprocessor.encode_input(sequence, pitcher_id)\n",
    "        padded_input = self.preprocessor.pad_sequence(encoded_input)\n",
    "        input_seq = torch.tensor(padded_input, dtype=torch.long).unsqueeze(0)\n",
    "        return input_seq\n",
    "    \n",
    "    def get_next_pitch_probs_for_pitcher(self, sequence, pitcher_id, should_mask=True):\n",
    "        input_seq = self.get_input_sequence_for_pitcher_prediction(sequence, pitcher_id)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_seq)\n",
    "            # The output shape should be [1, vocab_size]\n",
    "            logits = logits.squeeze(0)  # Remove batch dimension if present\n",
    "            if logits.dim() > 1:\n",
    "                logits = logits[-1]  # Take the last prediction if multiple outputs\n",
    "            \n",
    "            if should_mask:\n",
    "                arsenal_mask = self.preprocessor.get_pitcher_arsenal_mask(pitcher_id)\n",
    "                logits[~arsenal_mask.bool()] = float('-inf')\n",
    "\n",
    "            probabilities = torch.softmax(logits, dim=0)\n",
    "        \n",
    "        return probabilities\n",
    "\n",
    "\n",
    "    def predict_next_pitch_for_pitcher(self, sequence, pitcher_id, should_mask=True):\n",
    "        probabilities = self.get_next_pitch_probs_for_pitcher(sequence, pitcher_id, should_mask)\n",
    "        predicted_idx = torch.argmax(probabilities).item()\n",
    "\n",
    "        return self.preprocessor.idx_to_pitch[predicted_idx]\n",
    "    \n",
    "    def get_next_pitch_probs(self, sequence, pitcher_id, should_mask=True):\n",
    "        encoded_seq = self.preprocessor.encode_sequence(sequence)\n",
    "        padded_seq = self.preprocessor.pad_sequence(encoded_seq)\n",
    "        input_seq = torch.tensor(padded_seq, dtype=torch.long).unsqueeze(0)\n",
    "        \n",
    "\n",
    "        self.model.eval()  # Ensure the model is in evaluation mode\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_seq)\n",
    "            # The output shape should be [1, vocab_size]\n",
    "            logits = logits.squeeze(0)  # Remove batch dimension if present\n",
    "            if logits.dim() > 1:\n",
    "                logits = logits[-1]  # Take the last prediction if multiple outputs\n",
    "            \n",
    "            if should_mask:\n",
    "                arsenal_mask = self.preprocessor.get_pitcher_arsenal_mask(pitcher_id)\n",
    "                logits[~arsenal_mask.bool()] = float('-inf')\n",
    "\n",
    "            probabilities = torch.softmax(logits, dim=0)\n",
    "\n",
    "            return probabilities\n",
    "\n",
    "\n",
    "    def predict_next_pitch(self, sequence, pitcher_id, should_mask=True):\n",
    "        probabilities = self.get_next_pitch_probs(sequence, pitcher_id, should_mask)\n",
    "        predicted_idx = torch.argmax(probabilities).item()\n",
    "        return self.preprocessor.idx_to_pitch[predicted_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, lr, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            # Don't use arsenal mask for now.\n",
    "            input_seq, target = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                # Don't use arsenal mask for now.\n",
    "                input_seq, target = [b.to(device) for b in batch]\n",
    "                output = model(input_seq)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/sequence_data_opt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pitch Sequence</th>\n",
       "      <th>Pitcher ID</th>\n",
       "      <th>At-Bat Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI</td>\n",
       "      <td>621107</td>\n",
       "      <td>field_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI,CB,FC,SI,CB,SI,FF</td>\n",
       "      <td>621107</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST,ST,SI,SI,ST,ST</td>\n",
       "      <td>676534</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SI,ST,SI,ST,SI</td>\n",
       "      <td>687330</td>\n",
       "      <td>grounded_into_double_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FF,FF,FF,SL,FF,SL</td>\n",
       "      <td>477132</td>\n",
       "      <td>strikeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FF,FF,SL,FF,SL,SL</td>\n",
       "      <td>477132</td>\n",
       "      <td>strikeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FF,SL,CH,FF,CH,SL,FF,CH,CH,FF</td>\n",
       "      <td>656578</td>\n",
       "      <td>field_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FC,CH,CH,CH</td>\n",
       "      <td>608379</td>\n",
       "      <td>double_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FC,CH,FC</td>\n",
       "      <td>608379</td>\n",
       "      <td>field_out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FC,FC,CH</td>\n",
       "      <td>608379</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Pitch Sequence  Pitcher ID             At-Bat Outcome\n",
       "0                             SI      621107                field_error\n",
       "1           SI,CB,FC,SI,CB,SI,FF      621107                     single\n",
       "2              ST,ST,SI,SI,ST,ST      676534                       walk\n",
       "3                 SI,ST,SI,ST,SI      687330  grounded_into_double_play\n",
       "4              FF,FF,FF,SL,FF,SL      477132                  strikeout\n",
       "5              FF,FF,SL,FF,SL,SL      477132                  strikeout\n",
       "6  FF,SL,CH,FF,CH,SL,FF,CH,CH,FF      656578                field_error\n",
       "7                    FC,CH,CH,CH      608379                double_play\n",
       "8                       FC,CH,FC      608379                  field_out\n",
       "9                       FC,FC,CH      608379                     double"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "preprocessor = PitchDataPreprocessor(df)\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148430, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pitch Sequence</th>\n",
       "      <th>Pitcher ID</th>\n",
       "      <th>At-Bat Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101708</th>\n",
       "      <td>FF,SL,SL,FF,SL</td>\n",
       "      <td>600917</td>\n",
       "      <td>strikeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88766</th>\n",
       "      <td>SL,FF,CB,CB</td>\n",
       "      <td>670102</td>\n",
       "      <td>field_out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177432</th>\n",
       "      <td>SL</td>\n",
       "      <td>623352</td>\n",
       "      <td>force_out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146963</th>\n",
       "      <td>FF,FS,FS</td>\n",
       "      <td>592332</td>\n",
       "      <td>field_out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41087</th>\n",
       "      <td>SL,FF,SL,FF,SL,CB,FF,SL</td>\n",
       "      <td>674072</td>\n",
       "      <td>field_out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Pitch Sequence  Pitcher ID At-Bat Outcome\n",
       "101708           FF,SL,SL,FF,SL      600917      strikeout\n",
       "88766               SL,FF,CB,CB      670102      field_out\n",
       "177432                       SL      623352      force_out\n",
       "146963                 FF,FS,FS      592332      field_out\n",
       "41087   SL,FF,SL,FF,SL,CB,FF,SL      674072      field_out"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = PitchSequenceDataset(train_df.head(1000), preprocessor)\n",
    "test_dataset = PitchSequenceDataset(test_df.head(1000), preprocessor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/pitch-sequencing/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "vocab_size = len(preprocessor.pitch_to_idx)\n",
    "model = PitchTransformer(vocab_size, d_model=64, nhead=4, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 2.0549, Val Loss: 1.8795\n",
      "Epoch 2/25, Train Loss: 1.9274, Val Loss: 1.8778\n",
      "Epoch 3/25, Train Loss: 1.9339, Val Loss: 1.8629\n",
      "Epoch 4/25, Train Loss: 1.9144, Val Loss: 1.8517\n",
      "Epoch 5/25, Train Loss: 1.9020, Val Loss: 1.8681\n",
      "Epoch 6/25, Train Loss: 1.9094, Val Loss: 1.8569\n",
      "Epoch 7/25, Train Loss: 1.8985, Val Loss: 1.8557\n",
      "Epoch 8/25, Train Loss: 1.8912, Val Loss: 1.8765\n",
      "Epoch 9/25, Train Loss: 1.9180, Val Loss: 1.8496\n",
      "Epoch 10/25, Train Loss: 1.9075, Val Loss: 1.8483\n",
      "Epoch 11/25, Train Loss: 1.9060, Val Loss: 1.8649\n",
      "Epoch 12/25, Train Loss: 1.9049, Val Loss: 1.8474\n",
      "Epoch 13/25, Train Loss: 1.9068, Val Loss: 1.8646\n",
      "Epoch 14/25, Train Loss: 1.9082, Val Loss: 1.8492\n",
      "Epoch 15/25, Train Loss: 1.8987, Val Loss: 1.8500\n",
      "Epoch 16/25, Train Loss: 1.9016, Val Loss: 1.8496\n",
      "Epoch 17/25, Train Loss: 1.8916, Val Loss: 1.8456\n",
      "Epoch 18/25, Train Loss: 1.8927, Val Loss: 1.8493\n",
      "Epoch 19/25, Train Loss: 1.8955, Val Loss: 1.8445\n",
      "Epoch 20/25, Train Loss: 1.8907, Val Loss: 1.8474\n",
      "Epoch 21/25, Train Loss: 1.9123, Val Loss: 1.8466\n",
      "Epoch 22/25, Train Loss: 1.9095, Val Loss: 1.8596\n",
      "Epoch 23/25, Train Loss: 1.9056, Val Loss: 1.8439\n",
      "Epoch 24/25, Train Loss: 1.8964, Val Loss: 1.8472\n",
      "Epoch 25/25, Train Loss: 1.8948, Val Loss: 1.8471\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_model = train_model(model, train_loader, test_loader, num_epochs=25, lr=0.001, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PitchPredictor(trained_model, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Pitch Probs Unmasked: tensor([1.0534e-04, 7.3921e-05, 1.2012e-04, 1.1442e-01, 4.7350e-02, 1.7856e-01,\n",
      "        5.9544e-05, 1.4699e-01, 8.0721e-02, 8.5688e-04, 3.3405e-01, 2.9481e-02,\n",
      "        6.7204e-02])\n",
      "Predicted next pitch Unmasked: FF\n",
      "Predicted Next Pitch Probs Masked: tensor([2.3926e-04, 1.6790e-04, 2.7282e-04, 2.5989e-01, 0.0000e+00, 4.0557e-01,\n",
      "        0.0000e+00, 3.3386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00])\n",
      "Predicted next pitch Masked: SL\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "sequence = \"SL,CH\"\n",
    "pitcher_id = 623352\n",
    "next_pitch_masked = predictor.predict_next_pitch(sequence, pitcher_id, should_mask=True)\n",
    "next_pitch_unmasked = predictor.predict_next_pitch(sequence, pitcher_id, should_mask=False)\n",
    "print(f\"Predicted Next Pitch Probs Unmasked: {predictor.get_next_pitch_probs(sequence, pitcher_id, should_mask=False)}\")\n",
    "print(f\"Predicted next pitch Unmasked: {next_pitch_unmasked}\")\n",
    "print(f\"Predicted Next Pitch Probs Masked: {predictor.get_next_pitch_probs(sequence, pitcher_id)}\")\n",
    "print(f\"Predicted next pitch Masked: {next_pitch_masked}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with adding arsenal as encoded input to our model\n",
    "Input sequence will look like \n",
    "\n",
    "```<arsenal><pitch id><pitch_id><pitch id>...<pad up to max arsenal len> <start> <pitch ids in sequence> <pad to max length>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "p_train_dataset = PitchSequenceAndPitcherDataset(train_df.head(1000), preprocessor)\n",
    "p_test_dataset = PitchSequenceAndPitcherDataset(test_df.head(1000), preprocessor)\n",
    "p_train_loader = DataLoader(p_train_dataset, batch_size=32, shuffle=True)\n",
    "p_test_loader = DataLoader(p_test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "vocab_size = len(preprocessor.pitch_to_idx)\n",
    "arsenal_model = PitchTransformer(vocab_size, d_model=64, nhead=4, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 2.0131, Val Loss: 1.8754\n",
      "Epoch 2/25, Train Loss: 1.9246, Val Loss: 1.8593\n",
      "Epoch 3/25, Train Loss: 1.9052, Val Loss: 1.8595\n",
      "Epoch 4/25, Train Loss: 1.9067, Val Loss: 1.8610\n",
      "Epoch 5/25, Train Loss: 1.9008, Val Loss: 1.8574\n",
      "Epoch 6/25, Train Loss: 1.9039, Val Loss: 1.8756\n",
      "Epoch 7/25, Train Loss: 1.9060, Val Loss: 1.8658\n",
      "Epoch 8/25, Train Loss: 1.9127, Val Loss: 1.8569\n",
      "Epoch 9/25, Train Loss: 1.9131, Val Loss: 1.8684\n",
      "Epoch 10/25, Train Loss: 1.8974, Val Loss: 1.8681\n",
      "Epoch 11/25, Train Loss: 1.9032, Val Loss: 1.8552\n",
      "Epoch 12/25, Train Loss: 1.9067, Val Loss: 1.8709\n",
      "Epoch 13/25, Train Loss: 1.9124, Val Loss: 1.8582\n",
      "Epoch 14/25, Train Loss: 1.8872, Val Loss: 1.8561\n",
      "Epoch 15/25, Train Loss: 1.8993, Val Loss: 1.8467\n",
      "Epoch 16/25, Train Loss: 1.9183, Val Loss: 1.8522\n",
      "Epoch 17/25, Train Loss: 1.8978, Val Loss: 1.8529\n",
      "Epoch 18/25, Train Loss: 1.8986, Val Loss: 1.8542\n",
      "Epoch 19/25, Train Loss: 1.8948, Val Loss: 1.8475\n",
      "Epoch 20/25, Train Loss: 1.8949, Val Loss: 1.8516\n",
      "Epoch 21/25, Train Loss: 1.8903, Val Loss: 1.8484\n",
      "Epoch 22/25, Train Loss: 1.8937, Val Loss: 1.8458\n",
      "Epoch 23/25, Train Loss: 1.8937, Val Loss: 1.8443\n",
      "Epoch 24/25, Train Loss: 1.8876, Val Loss: 1.8513\n",
      "Epoch 25/25, Train Loss: 1.8956, Val Loss: 1.8497\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_arsenal_model = train_model(arsenal_model, p_train_loader, p_test_loader, num_epochs=25, lr=0.001, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "arsenal_predictor = PitchPredictor(trained_arsenal_model, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CH', 'SI', 'SL'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.pitcher_arsenals[623352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Pitch Probs Unmasked: tensor([1.2956e-04, 1.4132e-04, 1.2171e-04, 1.0859e-01, 5.2791e-02, 1.7378e-01,\n",
      "        1.0648e-04, 1.9605e-01, 7.2606e-02, 1.0102e-03, 2.9750e-01, 2.9522e-02,\n",
      "        6.7646e-02])\n",
      "Predicted next pitch Unmasked: FF\n",
      "Predicted Next Pitch Probs Masked: tensor([2.7058e-04, 2.9513e-04, 2.5418e-04, 2.2679e-01, 0.0000e+00, 3.6293e-01,\n",
      "        0.0000e+00, 4.0945e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00])\n",
      "Predicted next pitch Masked: SI\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "sequence = \"SL,CH\"\n",
    "pitcher_id = 623352\n",
    "next_pitch_masked = arsenal_predictor.predict_next_pitch_for_pitcher(sequence, pitcher_id, should_mask=True)\n",
    "next_pitch_unmasked = arsenal_predictor.predict_next_pitch_for_pitcher(sequence, pitcher_id, should_mask=False)\n",
    "print(f\"Predicted Next Pitch Probs Unmasked: {arsenal_predictor.get_next_pitch_probs_for_pitcher(sequence, pitcher_id, should_mask=False)}\")\n",
    "print(f\"Predicted next pitch Unmasked: {next_pitch_unmasked}\")\n",
    "print(f\"Predicted Next Pitch Probs Masked: {arsenal_predictor.get_next_pitch_probs_for_pitcher(sequence, pitcher_id)}\")\n",
    "print(f\"Predicted next pitch Masked: {next_pitch_masked}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some sanity output checks for arsenal encoded input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 5, 7, 0, 0, 0, 0, 0, 1, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"SL,CH\"\n",
    "pitcher_id = 623352\n",
    "predictor.get_input_sequence_for_pitcher_prediction(sequence, pitcher_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch-sequencing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
